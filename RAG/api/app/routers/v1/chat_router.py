"""
FastAPI ê¸°ì¤€ì˜ API ì—”ë“œí¬ì¸íŠ¸ ê³„ì¸µì…ë‹ˆë‹¤.

chat_router.py
POST /api/chain
ì„¸ì…˜ ID, ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ë“±ì„ ë°›ì•„ ëŒ€í™”í˜• ì‘ë‹µ ë°˜í™˜.
"""

import os

# ìŠ¤í‚¤ë§ˆ import
from app.domains.v1.chat.models.base_model import ChatRequest, ChatResponse
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from langchain_core.messages import AIMessage, HumanMessage
import asyncio

router = APIRouter(prefix="/api", tags=["chat"])


def get_chat_service():
    """ChatService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.

    ì´ í•¨ìˆ˜ëŠ” main.pyì˜ ì „ì—­ ë³€ìˆ˜ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´
    main ëª¨ë“ˆì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•©ë‹ˆë‹¤.
    """
    # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import
    import sys

    # main ëª¨ë“ˆì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if "app.main" in sys.modules:
        from ... import main
    else:
        # ëª¨ë“ˆì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ì§ì ‘ import
        import importlib

        main = importlib.import_module("app.main")

    return main.chat_service


@router.post("/chain", response_model=ChatResponse)
async def chat(request: ChatRequest, http_request: Request):
    """ì±—ë´‡ API ì—”ë“œí¬ì¸íŠ¸ - ChatServiceë¥¼ ì‚¬ìš©í•œ RAG ì²´ì¸."""
    # ChatService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    chat_service = get_chat_service()
    if chat_service is None:
        raise HTTPException(
            status_code=503,
            detail="ChatServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.",
        )

    # ìš”ì²­ìì˜ IP ì£¼ì†Œ í™•ì¸ (localhost ì—¬ë¶€ íŒë‹¨)
    client_host = http_request.client.host if http_request.client else None
    is_localhost = (
        client_host == "127.0.0.1"
        or client_host == "localhost"
        or client_host == "::1"
        or (client_host and client_host.startswith("127."))
    )

    # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ RAG ì²´ì¸ ì„ íƒ
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ model_typeì´ ì—†ìœ¼ë©´ .envì˜ LLM_PROVIDER ì‚¬ìš©
    model_type = request.model_type or os.getenv("LLM_PROVIDER", "openai")
    if model_type:
        model_type = model_type.lower()

    # í™˜ê²½ê³¼ ëª¨ë¸ íƒ€ì… ë¶ˆì¼ì¹˜ ê²€ì¦
    if is_localhost and model_type == "openai":
        raise HTTPException(
            status_code=400,
            detail="í˜„ì¬ ë¡œì»¬í™˜ê²½ì…ë‹ˆë‹¤. ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
        )

    if not is_localhost and model_type in ["local", "graph"]:
        raise HTTPException(
            status_code=400,
            detail="í˜„ì¬ ë¡œì»¬ í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
        )

    # ë””ë²„ê¹…: ë°›ì€ model_type ë¡œê·¸ ì¶œë ¥
    print(
        f"[DEBUG] ë°›ì€ model_type: {request.model_type}, ì²˜ë¦¬ëœ model_type: {model_type}, client_host: {client_host}, is_localhost: {is_localhost}"
    )

    try:
        # graph ëª¨ë“œì¼ ë•ŒëŠ” LangGraph ì‚¬ìš© (Exaone ëª¨ë¸)
        if model_type == "graph":
            print("[DEBUG] graph ëª¨ë“œ ê°ì§€ - LangGraph (Exaone) ì‚¬ìš©")
            from app.domains.v1.chat.agents.graph import run_once

            response_text = run_once(request.message)
            return ChatResponse(response=response_text)

        # ê·¸ ì™¸ ëª¨ë“œëŠ” ChatServiceë¥¼ í†µí•´ RAG ì²´ì¸ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ìƒì„±
        async def stream_response():
            try:
                # ì ì ˆí•œ RAG ì²´ì¸ ì„ íƒ
                if model_type == "openai":
                    if not chat_service.openai_rag_chain:
                        if chat_service.openai_quota_exceeded:
                            yield "OpenAI API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
                            return
                        else:
                            yield "OpenAI RAG ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                            return
                    current_rag_chain = chat_service.openai_rag_chain
                elif model_type == "local":
                    if not chat_service.local_rag_chain:
                        yield "ë¡œì»¬ RAG ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                        return
                    current_rag_chain = chat_service.local_rag_chain
                else:
                    yield f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì…ë‹ˆë‹¤: {model_type}"
                    return

                # ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                chat_history = []
                if request.history:
                    for msg in request.history:
                        if msg.get("role") == "user":
                            chat_history.append(HumanMessage(content=msg.get("content", "")))
                        elif msg.get("role") == "assistant":
                            chat_history.append(AIMessage(content=msg.get("content", "")))

                # RAG ì²´ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
                accumulated_text = ""
                full_response = ""
                async for chunk in current_rag_chain.astream(
                    {
                        "input": request.message,
                        "chat_history": chat_history,
                    }
                ):
                    # chunkì—ì„œ answer ì¶”ì¶œ
                    if isinstance(chunk, dict):
                        answer = chunk.get("answer", "")
                        if answer:
                            full_response = answer
                            # ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                            if len(answer) > len(accumulated_text):
                                delta = answer[len(accumulated_text):]
                                accumulated_text = answer
                                # í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë°
                                for char in delta:
                                    yield char
                                    await asyncio.sleep(0.01)
                    elif isinstance(chunk, str):
                        full_response = chunk
                        if len(chunk) > len(accumulated_text):
                            delta = chunk[len(accumulated_text):]
                            accumulated_text = chunk
                            # í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë°
                            for char in delta:
                                yield char
                                await asyncio.sleep(0.01)

                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µ ì •ë¦¬ (íƒœê·¸ ì œê±° ë“±)
                # ì´ë¯¸ chat_with_ragì—ì„œ ì •ë¦¬í•˜ì§€ë§Œ, ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” ì§ì ‘ ì²˜ë¦¬í•˜ë¯€ë¡œ
                # ì—¬ê¸°ì„œë„ ì •ë¦¬ ë¡œì§ì„ ì ìš©í•  ìˆ˜ ìˆìŒ (ì„ íƒì‚¬í•­)

            except Exception as e:
                error_msg = str(e)
                print(f"[ERROR] ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {error_msg}")
                yield f"\n\n[ì˜¤ë¥˜ ë°œìƒ: {error_msg}]"

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        return StreamingResponse(
            stream_response(),
            media_type="text/plain; charset=utf-8",
        )

    except ValueError as e:
        error_msg = str(e)
        print(f"[ERROR] ì˜ëª»ëœ ìš”ì²­: {error_msg}")
        raise HTTPException(
            status_code=400,
            detail=error_msg,
        )

    except Exception as e:
        error_msg = str(e)
        print(f"[ERROR] ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {error_msg}")

        # OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì—ëŸ¬ í™•ì¸ (1ë²ˆë§Œ ì²´í¬)
        if (
            "í• ë‹¹ëŸ‰" in error_msg
            or "quota" in error_msg.lower()
            or "429" in error_msg
            or "insufficient_quota" in error_msg
            or "exceeded" in error_msg.lower()
        ):
            error_detail = (
                "âš ï¸ OpenAI API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                "í•´ê²° ë°©ë²•:\n"
                "1. OpenAI ê³„ì •ì˜ ì‚¬ìš©ëŸ‰ ë° í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”\n"
                "2. OpenAI ê³„ì •ì— ê²°ì œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ í• ë‹¹ëŸ‰ì„ ëŠ˜ë¦¬ì„¸ìš”\n"
                "3. ë˜ëŠ” 'ğŸ–¥ï¸ ë¡œì»¬ ëª¨ë¸' ë²„íŠ¼ì„ ì„ íƒí•˜ì—¬ ë¡œì»¬ Midm ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”"
            )
            raise HTTPException(
                status_code=429,
                detail=error_detail,
            )
        else:
            # RuntimeErrorëŠ” 503, ê¸°íƒ€ëŠ” 500
            status_code = 503 if isinstance(e, RuntimeError) else 500
            raise HTTPException(
                status_code=status_code,
                detail=f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg[:200]}",
            )
