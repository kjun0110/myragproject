"""
LangChainê³¼ pgvector ì—°ê²° ì›Œì»¤.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LangChainê³¼ PostgreSQL pgvector í™•ì¥ì„ ì—°ê²°í•˜ì—¬
ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ì—­í• :
- PostgreSQL pgvectorì™€ì˜ ì—°ê²° ê´€ë¦¬
- ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ë°ì´í„° ê´€ë¦¬
- ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§
"""

import os
import time
import warnings
from pathlib import Path
from typing import List

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°)
try:
    from dotenv import load_dotenv

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (api/app/ -> api/ -> í”„ë¡œì íŠ¸ ë£¨íŠ¸)
    current_file = Path(__file__)
    project_root = current_file.parent.parent.parent
    env_file = project_root / ".env"

    if env_file.exists():
        load_dotenv(env_file)
    else:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œë„ ì‹œë„
        load_dotenv()
except ImportError:
    pass  # python-dotenvê°€ ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ë§Œ ì‚¬ìš©

# PGVectorì˜ JSONB deprecation ê²½ê³  ë¬´ì‹œ
try:
    from langchain_core._api.deprecation import LangChainPendingDeprecationWarning

    warnings.filterwarnings(
        "ignore",
        category=LangChainPendingDeprecationWarning,
        module="langchain_community.vectorstores.pgvector",
    )
except ImportError:
    # langchain_coreê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ DeprecationWarning ë¬´ì‹œ
    warnings.filterwarnings(
        "ignore",
        category=DeprecationWarning,
        module="langchain_community.vectorstores.pgvector",
    )

# ì¼ë°˜ DeprecationWarningë„ ë¬´ì‹œ
warnings.filterwarnings(
    "ignore",
    category=DeprecationWarning,
    module="langchain_community.vectorstores.pgvector",
)

from langchain_community.vectorstores import PGVector
from langchain_core.documents import Document
from langchain_core.embeddings import FakeEmbeddings
from langchain_openai import OpenAIEmbeddings

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass  # python-dotenvê°€ ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ë§Œ ì‚¬ìš©

# Neon PostgreSQL ì—°ê²° ë¬¸ìì—´ (.env íŒŒì¼ì˜ DATABASE_URL ì‚¬ìš©)
DATABASE_URL = os.getenv("DATABASE_URL")
SSLMODE = os.getenv("sslmode", "require")

if DATABASE_URL:
    # DATABASE_URLì— sslmodeê°€ ì—†ìœ¼ë©´ ì¶”ê°€
    if "sslmode=" not in DATABASE_URL:
        separator = "&" if "?" in DATABASE_URL else "?"
        CONNECTION_STRING = f"{DATABASE_URL}{separator}sslmode={SSLMODE}"
    else:
        CONNECTION_STRING = DATABASE_URL
else:
    # ê¸°ë³¸ê°’ (fallback)
    CONNECTION_STRING = os.getenv(
        "POSTGRES_CONNECTION_STRING",
        "postgresql://neondb_owner:npg_bNXv7Ll1mrBJ@ep-empty-tree-a15rzl4v-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require",
    )

COLLECTION_NAME = "langchain_collection"


def wait_for_postgres(max_retries: int = 30, delay: int = 2) -> None:
    """Neon PostgreSQLì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°."""
    import psycopg2

    for i in range(max_retries):
        try:
            conn = psycopg2.connect(CONNECTION_STRING)
            conn.close()
            print("âœ“ Neon PostgreSQL ì—°ê²° ì„±ê³µ!")
            return
        except Exception as e:
            if i < max_retries - 1:
                print(f"Neon PostgreSQL ëŒ€ê¸° ì¤‘... ({i + 1}/{max_retries})")
                time.sleep(delay)
            else:
                raise ConnectionError(f"Neon PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")


def main() -> None:
    """LangChain Hello World ë©”ì¸ í•¨ìˆ˜."""
    print("=" * 50)
    print("LangChain Hello World with pgvector")
    print("=" * 50)

    # Neon PostgreSQL ì—°ê²° ëŒ€ê¸°
    print("\n1. Neon PostgreSQL ì—°ê²° í™•ì¸ ì¤‘...")
    wait_for_postgres()

    # Embedding ëª¨ë¸ ì´ˆê¸°í™” (OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ FakeEmbeddings ì‚¬ìš©)
    print("\n2. Embedding ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    embeddings = None

    if openai_api_key and openai_api_key != "your-api-key-here":
        try:
            # OpenAIEmbeddings ì´ˆê¸°í™” ë° ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            test_embeddings = OpenAIEmbeddings()
            # ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (í• ë‹¹ëŸ‰ í™•ì¸)
            test_embeddings.embed_query("test")
            embeddings = test_embeddings
            print("âœ“ OpenAI Embedding ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            error_msg = str(e)
            if (
                "quota" in error_msg.lower()
                or "429" in error_msg
                or "insufficient_quota" in error_msg
            ):
                print(f"âš  OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼: {error_msg[:100]}...")
            else:
                print(f"âš  OpenAI Embedding ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {error_msg[:100]}...")
            print("   FakeEmbeddingsë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
            embeddings = FakeEmbeddings(size=1536)
            print("âœ“ FakeEmbeddings ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        print("   OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. FakeEmbeddingsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        embeddings = FakeEmbeddings(size=1536)
        print("âœ“ FakeEmbeddings ì´ˆê¸°í™” ì™„ë£Œ")

    # PGVector ìŠ¤í† ì–´ ìƒì„±
    print("\n3. PGVector ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    try:
        vector_store = PGVector.from_documents(
            embedding=embeddings,
            documents=[
                Document(
                    page_content="LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
                    metadata={"source": "intro"},
                ),
                Document(
                    page_content="pgvectorëŠ” PostgreSQLì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.",
                    metadata={"source": "pgvector"},
                ),
                Document(
                    page_content="Hello WorldëŠ” í”„ë¡œê·¸ë˜ë°ì˜ ì²« ë²ˆì§¸ ì˜ˆì œì…ë‹ˆë‹¤.",
                    metadata={"source": "hello"},
                ),
            ],
            collection_name=COLLECTION_NAME,
            connection_string=CONNECTION_STRING,
        )
        print("âœ“ PGVector ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        error_msg = str(e)
        # OpenAI API ì˜¤ë¥˜ì¸ ê²½ìš° FakeEmbeddingsë¡œ ì¬ì‹œë„
        if (
            "quota" in error_msg.lower()
            or "429" in error_msg
            or "insufficient_quota" in error_msg
        ):
            print("âš  OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ì¸í•œ ì˜¤ë¥˜ ë°œìƒ")
            print("   FakeEmbeddingsë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            try:
                embeddings = FakeEmbeddings(size=1536)
                vector_store = PGVector.from_documents(
                    embedding=embeddings,
                    documents=[
                        Document(
                            page_content="LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
                            metadata={"source": "intro"},
                        ),
                        Document(
                            page_content="pgvectorëŠ” PostgreSQLì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.",
                            metadata={"source": "pgvector"},
                        ),
                        Document(
                            page_content="Hello WorldëŠ” í”„ë¡œê·¸ë˜ë°ì˜ ì²« ë²ˆì§¸ ì˜ˆì œì…ë‹ˆë‹¤.",
                            metadata={"source": "hello"},
                        ),
                    ],
                    collection_name=COLLECTION_NAME,
                    connection_string=CONNECTION_STRING,
                )
                print("âœ“ FakeEmbeddingsë¡œ PGVector ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
            except Exception as retry_error:
                print(f"âœ— FakeEmbeddingsë¡œë„ PGVector ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {retry_error}")
                return
        else:
            print(f"âœ— PGVector ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {error_msg[:200]}...")
            return

    # ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n4. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘...")
    try:
        query = "í”„ë ˆì„ì›Œí¬"
        results: List[Document] = vector_store.similarity_search(query, k=2)

        print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        print(f"ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):")
        for i, doc in enumerate(results, 1):
            print(f"\n  [{i}] {doc.page_content}")
            print(f"      ë©”íƒ€ë°ì´í„°: {doc.metadata}")
    except Exception as e:
        print(f"âœ— ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return

    print("\n" + "=" * 50)
    print("âœ“ LangChain Hello World ì™„ë£Œ!")
    print("=" * 50)

    # ì»¨í…Œì´ë„ˆê°€ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ ëŒ€ê¸° ë° PGVector ë°ì´í„° ì£¼ê¸°ì  ì¡°íšŒ
    print("\n" + "=" * 50)
    print("PGVector ì—°ê²° ëª¨ë‹ˆí„°ë§ ì‹œì‘... (ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+C)")
    print("=" * 50)

    check_count = 0
    try:
        while True:
            time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ë°ì´í„° ì¡°íšŒ
            check_count += 1

            print(f"\n[{check_count}] PGVector ë°ì´í„° ì¡°íšŒ ì¤‘...")
            print("-" * 50)

            try:
                # PGVectorì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ (ë”ë¯¸ ì¿¼ë¦¬ë¡œ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°)
                # similarity_searchë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¡°íšŒ
                test_queries = ["LangChain", "pgvector", "Hello", "í”„ë ˆì„ì›Œí¬"]

                for query in test_queries:
                    try:
                        query_results: List[Document] = vector_store.similarity_search(
                            query, k=3
                        )
                        print(f"\n  ì¿¼ë¦¬: '{query}' â†’ {len(query_results)}ê°œ ê²°ê³¼")
                        for i, doc in enumerate(
                            query_results[:2], 1
                        ):  # ìµœëŒ€ 2ê°œë§Œ ì¶œë ¥
                            print(f"    [{i}] {doc.page_content[:60]}...")
                            print(f"        ë©”íƒ€ë°ì´í„°: {doc.metadata}")
                    except Exception as e:
                        print(f"    âš  ì¿¼ë¦¬ '{query}' ì‹¤íŒ¨: {e}")

                # Neon PostgreSQLì—ì„œ ì§ì ‘ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                try:
                    import psycopg2

                    conn = psycopg2.connect(CONNECTION_STRING)
                    cursor = conn.cursor()

                    # PGVector í…Œì´ë¸” êµ¬ì¡° í™•ì¸ ë° ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ
                    # langchain_pg_embeddingê³¼ langchain_pg_collection í…Œì´ë¸” ì‚¬ìš©
                    try:
                        cursor.execute(
                            """
                            SELECT COUNT(*)
                            FROM langchain_pg_embedding
                            WHERE collection_id = (
                                SELECT uuid FROM langchain_pg_collection WHERE name = %s
                            )
                            """,
                            (COLLECTION_NAME,),
                        )
                        result = cursor.fetchone()
                        count = result[0] if result else 0
                    except Exception:
                        # í…Œì´ë¸” ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
                        cursor.execute(
                            "SELECT COUNT(*) FROM information_schema.tables "
                            "WHERE table_schema = 'public' AND table_name LIKE '%embedding%'"
                        )
                        result = cursor.fetchone()
                        count = result[0] if result else "í™•ì¸ ë¶ˆê°€"

                    cursor.close()
                    conn.close()

                    print("\n  ğŸ“Š PGVector ì €ì¥ì†Œ í†µê³„:")
                    print(f"     - ì»¬ë ‰ì…˜: {COLLECTION_NAME}")
                    print(f"     - ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {count}ê°œ")
                    print("     - PostgreSQL ì—°ê²°: âœ“ ì •ìƒ")
                except Exception as db_error:
                    print(f"\n  ğŸ“Š Neon PostgreSQL ì§ì ‘ ì¡°íšŒ ì‹¤íŒ¨: {db_error}")
                    print("     - PGVector ê²€ìƒ‰ì€ ì •ìƒ ì‘ë™ ì¤‘")

                print("-" * 50)

            except Exception as e:
                print(f"  âœ— PGVector ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
                print(f"     ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")

    except KeyboardInterrupt:
        print("\n\nì»¨í…Œì´ë„ˆ ì¢…ë£Œ ì¤‘...")


if __name__ == "__main__":
    main()
